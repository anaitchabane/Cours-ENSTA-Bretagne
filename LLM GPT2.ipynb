{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7182523c",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Installation (si nécessaire) et imports\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5343fbd2",
   "metadata": {},
   "source": [
    "- transformers = librairie de Hugging Face, standard pour LLMs open-source.\n",
    "\n",
    "- pipeline = interface haut niveau qui encapsule :\n",
    "  1- le modèle,\n",
    "  2- le tokenizer,\n",
    "  3- la logique d’inférence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a97cba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairie 'transformers' chargée.\n"
     ]
    }
   ],
   "source": [
    "# Si transformers n'est pas installé dans l'environnement :\n",
    "# !pip install transformers\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"Librairie 'transformers' chargée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22052ecd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa4d50b5",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Création d'un pipeline de génération de texte\n",
    "\n",
    "task=\"text-generation\" → pipeline adapté aux modèles auto-régressifs (type GPT).\n",
    "\n",
    "model=\"gpt2\" → modèle de base (≈ 124M paramètres), pré-entraîné sur un large corpus anglais.\n",
    "\n",
    "Le téléchargement du modèle se fait automatiquement la première fois (si connexion Internet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4756bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x0000026CF8205C10>\n"
     ]
    }
   ],
   "source": [
    "# On crée un \"pipeline\" pour la tâche de génération de texte.\n",
    "# Le modèle choisi est \"gpt2\" (taille relativement petite pour une démo).\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\",  # type de tâche\n",
    "    model=\"gpt2\"             # nom du modèle pré-entraîné\n",
    ")\n",
    "\n",
    "print(generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d00f1",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Première génération de texte\n",
    "\n",
    "Entrée : un simple texte (le prompt).\n",
    "\n",
    "Sortie : une continuation du texte, en anglais (GPT-2 est entraîné sur de l’anglais).\n",
    "\n",
    "max_length inclut le texte du prompt.\n",
    "\n",
    "num_return_sequences permet de demander plusieurs variantes avec les mêmes paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d290e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt : Large language model\n",
      "\n",
      "Texte généré :\n",
      "\n",
      "Large language model.\n",
      "\n",
      "The game itself, which is playable in English, has a lot in common with the previous games in the series, but it is also far more complex.\n",
      "\n",
      "The game takes place in a fictional city with buildings that you can choose from. In most of the buildings there are specific sections that you must take down, but the game does not take you to all sections, as you must complete them. The game also has very limited resources, because each of the buildings has a unique set of resources.\n",
      "\n",
      "In order to achieve the same goal as the classic first-person shooter, you must also have a good level design. The game is based on a 3D layout. You can choose to build your own building, but you must have a good level design. The game is designed to be played as single player. The levels are usually well-designed, but there are some instances when you could have a lot of single player or multiplayer. The game is a good starting point for those that are interested in the game.\n",
      "\n",
      "The game's difficulty is relatively easy and the game itself is not a difficult game, but it is not as hard as it could be. There are many different types of enemies, which can be used to take down buildings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Large language model\"\n",
    "\n",
    "outputs = generator(\n",
    "    prompt,\n",
    "    max_length=50,   # longueur totale (prompt compris)\n",
    "    num_return_sequences=1  # nombre de variantes générées\n",
    ")\n",
    "\n",
    "print(\"Prompt :\", prompt)\n",
    "print(\"\\nTexte généré :\\n\")\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ddd6e70",
   "metadata": {},
   "source": [
    "\n",
    "contrairement au bigramme, le modèle traite sur une séquence plus longue,\n",
    "\n",
    "il s’appuie sur un vocabulaire de sous-mots (BPE),\n",
    "\n",
    "il a été entraîné sur un énorme corpus → savoir “statistique” du langage.\n",
    "\n",
    "GPT-2 n’a pas été entraîné pour “répondre”\n",
    "\n",
    "- Il n’a pas été entraîné pour :\n",
    "\n",
    "- suivre des instructions,\n",
    "\n",
    "- expliquer des concepts,\n",
    "\n",
    "Il a été entraîné uniquement à compléter du texte, sans comprendre l’intention de l’utilisateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8d086",
   "metadata": {},
   "source": [
    "# 4. Effet des paramètres de génération\n",
    "\n",
    "1- do_sample=True → on active le sampling (sinon c’est greedy / déterministe).\n",
    "\n",
    "2- temperature :\n",
    "- faible (0.3) → plus conservateur, textes plus “sages”,\n",
    "- intermédiaire (0.7) → bonne balance,\n",
    "- élevé (1.2) → plus créatif, mais plus de risques de dérive / incohérence.\n",
    "\n",
    "3- top_p=0.95 = nucleus sampling → on ne garde que les tokens cumulant 95% de la probabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a5ac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Température = 0.3\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the future, intelligent robots will be able to do things like pick up objects and move them around in a way that is more efficient than humans.\n",
      "\n",
      "\"We're going to see a lot of automation in the future,\" said Dr. David Z. Zimring, a professor of robotics at the University of California, Berkeley. \"We're going to see robots that can do things like pick up objects and move them around in a way that is more efficient than humans.\"\n",
      "\n",
      "The robots will also be able to do things like pick up objects and move them around in a way that is more efficient than humans.\n",
      "\n",
      "\"We're going to see robots that can do things like pick up objects and move them around in a way that is more efficient than humans,\" Zimring said.\n",
      "\n",
      "The robots will also be able to do things like pick up objects and move them around in a way that is more efficient than humans.\n",
      "\n",
      "\"We're going to see robots that can do things like pick up objects and move them around in a way that is more efficient than humans,\" Zimring said.\n",
      "\n",
      "The robots will also be able to do things like pick up objects and move them around in a way that is more efficient than humans.\n",
      "\n",
      "\"We're going to\n",
      "\n",
      "==============================\n",
      "Température = 0.7\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the future, intelligent robots will be able to take over our lives, including our lives. They will be capable of helping us build better cities and more affordable homes, and they will be able to be the first to make our communities more resilient.\n",
      "\n",
      "In addition, the robots will have an immense impact on the lives of those who work at our companies. They will help us to reduce our carbon footprint, and they will help us to protect our children and to protect the environment.\n",
      "\n",
      "The robots have also made our businesses more efficient. They have increased productivity by reducing our time spent in the office and by making it easier for us to manage our operations. They have also made it easier for us to manage our employees. And they have made it easier to do business with our neighbors, partners, and businesses.\n",
      "\n",
      "Robots will be able to create a better future for our country by helping us create a better tomorrow, by helping us create better lives for our children, and by helping us to create better schools and schools for our children.\n",
      "\n",
      "And the robots will help us to keep America safe.\n",
      "\n",
      "But if we do not act now, the robots will be too late.\n",
      "\n",
      "As I said, we have to stop worrying about how to do something about robots and start thinking\n",
      "\n",
      "==============================\n",
      "Température = 1.2\n",
      "==============================\n",
      "\n",
      "In the future, intelligent robots will be able to communicate directly with their owners, without humans interfering. In a sense, this means humanity is already \"wet\" about AI by this point, and that can have a long-term impact on human behavior.\n",
      "\n",
      "Of course, the most exciting aspect to this potential approach is that it also enables researchers to work with all kinds of robots. This means that a small group will benefit greatly — which is certainly a lot! At this point, it will only be a matter of time before the ability to \"read\" your emotions comes to the forefront of AI.\n",
      "\n",
      "Other Things to Consider:\n",
      "\n",
      "The use of \"intelligence\" by \"civilians\" and other things will change the social/cultural fabric of both cultures. Perhaps in the future, the \"human\" population won't just have access to any other language they'd prefer (like Wikipedia), but more importantly, they'll probably have language they can learn via other means such as email, video, video chat and on the Internet. If we take the notion of \"the good old days\" as proof that civilization's human capital has really turned out to be limited in part because human culture was first and foremost defined by their social capacities for speech, then these are truly two very different things.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"In the future, intelligent robots will\"\n",
    "\n",
    "for temperature in [0.3, 0.7, 1.2]:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Température = {temperature}\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_length=50,\n",
    "        do_sample=True,          # activation du sampling (sinon greedy)\n",
    "        temperature=temperature, # contrôle \"créativité\"\n",
    "        top_p=0.95,              # nucleus sampling\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab89c1fd",
   "metadata": {},
   "source": [
    "# 5-Comparer plusieurs sorties pour le même prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf4b5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt : In the factory of the future, humans and robots will\n",
      "\n",
      "--- Variantes générées ---\n",
      "\n",
      "### Variante 1 ###\n",
      "In the factory of the future, humans and robots will continue to struggle.\n",
      "\n",
      "For example, we're now doing everything to reduce our carbon footprint. While we're still building more power plants and cutting waste, we're working on smarter ways to get that cleaner energy out of the air.\n",
      "\n",
      "This means we're building our cars more energy-efficient. We're building cleaner cars that are less likely to smother air pollution, and we're using cleaner technology to reduce emissions—even from our homes.\n",
      "\n",
      "Today, even if our nation's energy footprint continues to drop, we're doing that because we're investing in the future. If we're going to grow into a more sustainable energy future, then we must have that future in mind.\n",
      "\n",
      "We need to embrace our future as a nation, not as a brand.\n",
      "\n",
      "We need not sell out to the world. We need to become a manufacturing center for our business. We need to embrace and grow our own energy.\n",
      "\n",
      "We need to make sure that our products are sustainable, but we also need to invest in renewable energy generation.\n",
      "\n",
      "That's why we've put forward many of our own economic solutions.\n",
      "\n",
      "We're putting forward our Climate Policy Goals.\n",
      "\n",
      "We've proposed a range of tax incentives to help invest in renewable\n",
      "\n",
      "### Variante 2 ###\n",
      "In the factory of the future, humans and robots will be able to accomplish their missions in tandem. But robots who don't have human capabilities will have to be the first to be called upon. The future of human education, however, won't be a place where students can sit in class and talk about their future.\n",
      "\n",
      "The Humanities Education Association, a nonprofit organization, recently launched a new initiative called \"No More Robots: The Future of Education and Human Development.\" The goal is to end the \"superclass mentality\" that has encouraged students to think like humans, and instead focus on the practical issues of education.\n",
      "\n",
      "\"We want to start to address the problem: what would happen if you were taught to think like a robot?\" says Dr. David Kesselman, president of the American Society of Human Engineers (ASHE), which created the initiative. \"So, in this context, we think robots are a potential solution to the problem of superclass.\"\n",
      "\n",
      "So, what happens if you're taught to think like a robot? For instance, a person might not think like a human. Or, if your teacher recommends you use a new type of tool, you might find yourself on the wrong side of the machine.\n",
      "\n",
      "But what if the teacher is wrong about your goal?\n",
      "\n",
      "That's\n",
      "\n",
      "### Variante 3 ###\n",
      "In the factory of the future, humans and robots will be part of the process. If we want to bring robots to the present day, then all humankind — that is, humans and robots — needs to come together — and develop a common project. The goal is to bring robots to the present day. The future is going to be a very good one.\n",
      "\n",
      "And if we're going to have a common project, the first thing we'd need is a common language or culture. And I think I have the idea if you think about what a common language or culture is today — and I think our ancestors did not have an ordinary language; they had a language of a couple millennia ago called Indo-European. So there were some people who came from northern Europe, some from western Europe, but none of them invented a common language, and so in a way it was a common cultural project, and most of the time you don't see anyone who invented a common culture creating it. So we would need a common language or culture, to bring people together and think about some common project.\n",
      "\n",
      "What we're trying to do, which is to do something that's called a new language, is to change how we think about writing and how we think about life. It's a very long thought that maybe we ought to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = \"In the factory of the future, humans and robots will\"\n",
    "\n",
    "outputs = generator(\n",
    "    prompt,\n",
    "    max_length=60,\n",
    "    do_sample=True,\n",
    "    temperature=0.8,\n",
    "    top_k=50,              # on limite aux 50 tokens les plus probables\n",
    "    num_return_sequences=3 # on demande 3 variantes\n",
    ")\n",
    "\n",
    "print(\"Prompt :\", prompt)\n",
    "print(\"\\n--- Variantes générées ---\\n\")\n",
    "for i, out in enumerate(outputs, 1):\n",
    "    print(f\"### Variante {i} ###\")\n",
    "    print(out[\"generated_text\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d67b6",
   "metadata": {},
   "source": [
    "\n",
    "# Remarques\n",
    "\n",
    "- Les trois réponses sont différentes → le modèle ne donne pas une “unique bonne réponse”.\n",
    "- Toute la génération est guidée par le prompt : si le prompt est flou, la réponse aussi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcec7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
