{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b35667",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Pourquoi tokeniser ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f1fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte brut :\n",
      "Les modèles de langage sont puissants.\n",
      "\n",
      "Remarque :\n",
      "Les modèles ne comprennent PAS directement le texte.\n",
      "Ils doivent le transformer en une séquence d'entiers : x1, x2, ..., xT.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = \"Les modèles de langage sont puissants.\"\n",
    "\n",
    "print(\"Texte brut :\")\n",
    "print(text)\n",
    "\n",
    "print(\"\\nRemarque :\")\n",
    "print(\"Les modèles ne comprennent PAS directement le texte.\")\n",
    "print(\"Ils doivent le transformer en une séquence d'entiers : x1, x2, ..., xT.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34bf0b6",
   "metadata": {},
   "source": [
    "## Remarques:\n",
    "\n",
    "1- Un LLM ne lit pas du texte, seulement des entiers.\n",
    "\n",
    "2- La tokenisation est la première étape pour transformer du texte → tokens → IDs.\n",
    "\n",
    "3- Différentes stratégies existent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa10e4",
   "metadata": {},
   "source": [
    "# Tokenisation naïve : mot-à-mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ddc8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenisation mot-à-mot :\n",
      "['Les', 'modèles', 'de', 'langage', 'sont', 'puissants.']\n",
      "\n",
      "Nombre de tokens : 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Les modèles de langage sont puissants.\"\n",
    "\n",
    "tokens = text.split()\n",
    "\n",
    "print(\"Tokenisation mot-à-mot :\")\n",
    "print(tokens)\n",
    "print(\"\\nNombre de tokens :\", len(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63424984",
   "metadata": {},
   "source": [
    "Ce qu’on observe :\n",
    "\n",
    "- Trop simple.\n",
    "\n",
    "- Sensible à la ponctuation (\"puissants.\" ≠ \"puissants\").\n",
    "\n",
    "- Impossible de gérer les fautes, variantes, néologismes.\n",
    "\n",
    "- Vocabulaire gigantesque → pas viable pour les LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc6c1e",
   "metadata": {},
   "source": [
    "# 3. Limites de la tokenisation mot-à-mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a2e9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot        -> ['robot']\n",
      "robots       -> ['robots']\n",
      "robotique    -> ['robotique']\n",
      "robotiques   -> ['robotiques']\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"robot\",\n",
    "    \"robots\",\n",
    "    \"robotique\",\n",
    "    \"robotiques\"\n",
    "]\n",
    "\n",
    "for t in texts:\n",
    "    print(f\"{t:12s} -> {t.split()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcaf5a5",
   "metadata": {},
   "source": [
    "# Remarques:\n",
    "\n",
    "Chaque forme est vue comme un mot différent → explosion du vocabulaire.\n",
    "\n",
    "Aucun partage d’information entre “robot”, “robots”, “robotique”…\n",
    "\n",
    "Dans une langue riche (français), c’est ingérable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2741508",
   "metadata": {},
   "source": [
    "# Tokenisation caractère par caractère"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fca3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r', 'o', 'b', 'o', 't', 'i', 'q', 'u', 'e']\n",
      "Nombre de 'tokens' : 9\n"
     ]
    }
   ],
   "source": [
    "text = \"robotique\"\n",
    "\n",
    "chars = list(text)\n",
    "print(chars)\n",
    "print(\"Nombre de 'tokens' :\", len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f115e",
   "metadata": {},
   "source": [
    "# Remarques:\n",
    "\n",
    "- Résout le problème du vocabulaire.\n",
    "- Mais rend la séquence trop longue.\n",
    "- Le modèle doit “réapprendre” toutes les combinaisons possibles → inefficace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724ca44",
   "metadata": {},
   "source": [
    "# Idée clé du BPE (Byte-Pair Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9831b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte-Pair Encoding (BPE) :\n",
      "- On commence avec des caractères.\n",
      "- On fusionne les paires les plus fréquentes.\n",
      "- On répète jusqu'à obtenir un vocabulaire de sous-mots.\n"
     ]
    }
   ],
   "source": [
    "print(\"Byte-Pair Encoding (BPE) :\")\n",
    "print(\"- On commence avec des caractères.\")\n",
    "print(\"- On fusionne les paires les plus fréquentes.\")\n",
    "print(\"- On répète jusqu'à obtenir un vocabulaire de sous-mots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc06f86",
   "metadata": {},
   "source": [
    "BPE est un compromis :\n",
    "\n",
    "- pas trop long (pas de caractères),\n",
    "- pas trop gros (pas de mot complet),\n",
    "- capable de gérer les mots inconnus → découpage en sous-unités."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cdc603",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Tokenisation BPE réelle (GPT-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d3088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte : internationalisation\n",
      "\n",
      "Tokens BPE : ['international', 'isation']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "text = \"internationalisation\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "print(\"Texte :\", text)\n",
    "print(\"\\nTokens BPE :\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb108ca",
   "metadata": {},
   "source": [
    "Remarques:\n",
    "    \n",
    "- Le modèle découpe en sous-mots du corpus BPE GPT-2.\n",
    "-  Le découpage peut être surprenant → dépend de la fréquence dans le corpus Web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2af849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Obtenir les IDs associés aux tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3788e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens : ['international', 'isation']\n",
      "IDs    : [45609, 5612]\n",
      "\n",
      "Nombre de tokens BPE : 2\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(text)\n",
    "\n",
    "print(\"Tokens :\", tokens)\n",
    "print(\"IDs    :\", ids)\n",
    "print(\"\\nNombre de tokens BPE :\", len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Comparer la tokenisation sur plusieurs phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9fbaae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phrase : robot\n",
      "Tokens : ['ro', 'bot']\n",
      "IDs    : [305, 13645]\n",
      "\n",
      "=== Phrase : robotique\n",
      "Tokens : ['ro', 'bot', 'ique']\n",
      "IDs    : [305, 13645, 2350]\n",
      "\n",
      "=== Phrase : robots industriels\n",
      "Tokens : ['rob', 'ots', 'Ġindust', 'ri', 'els']\n",
      "IDs    : [22609, 1747, 2226, 380, 1424]\n",
      "\n",
      "=== Phrase : Les humanoïdes collaborent avec les humains.\n",
      "Tokens : ['Les', 'Ġhuman', 'o', 'Ã¯', 'des', 'Ġcoll', 'ab', 'ore', 'nt', 'Ġa', 'vec', 'Ġles', 'Ġhum', 'ains', '.']\n",
      "IDs    : [35882, 1692, 78, 26884, 8906, 2927, 397, 382, 429, 257, 35138, 10287, 1311, 1299, 13]\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"robot\",\n",
    "    \"robotique\",\n",
    "    \"robots industriels\",\n",
    "    \"Les humanoïdes collaborent avec les humains.\"\n",
    "]\n",
    "\n",
    "for t in examples:\n",
    "    print(\"\\n=== Phrase :\", t)\n",
    "    print(\"Tokens :\", tokenizer.tokenize(t))\n",
    "    print(\"IDs    :\", tokenizer.encode(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f2dc7",
   "metadata": {},
   "source": [
    "# Remarques\n",
    "\n",
    "- Certains mots sont coupés (Ġrobots, industri, els)\n",
    "- Les espaces sont codés avec un préfixe spécial (Ġ)\n",
    "- Les mots inconnus sont décomposés en sous-unités → robustesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ff071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
